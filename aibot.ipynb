{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#### Import libraries"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import requests\n",
    "import bs4 as bs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Creating the Corpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "response = requests.get('https://en.wikipedia.org/wiki/Pythagoras')\n",
    "raw_html = response.text\n",
    "\n",
    "article_html = bs.BeautifulSoup(raw_html, 'html')\n",
    "article_paragraphs = article_html.find_all('p')\n",
    "\n",
    "article_text = ''.join(p.text for p in article_paragraphs).lower()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pythagoras of samos[a] (c. 570 – c. 495 bc)[b] wa\n"
     ]
    }
   ],
   "source": [
    "print(article_text[:50])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Text Preprocessing\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pythagoras of samos[a] (c. 570 – c. 495 bc)[b] wa\n"
     ]
    }
   ],
   "source": [
    "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
    "article_text = re.sub(r'\\s+', ' ', article_text)\n",
    "print(article_text[:50])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Divide to sentence\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pythagoras of samos[a] (c. 570 – c. 495 bc)[b] was an ancient ionian greek philosopher and the eponymous founder of pythagoreanism.\n",
      "his political and religious teachings were well known in magna graecia and influenced the philosophies of plato, aristotle, and, through them, western philosophy.\n",
      "knowledge of his life is clouded by legend, but he appears to have been the son of mnesarchus, a gem-engraver on the island of samos.\n"
     ]
    }
   ],
   "source": [
    "article_sentence = nltk.sent_tokenize(article_text)\n",
    "\n",
    "for sentence in article_sentence[:3]:\n",
    "    print(sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Divide to words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pythagoras', 'of', 'samos']\n"
     ]
    }
   ],
   "source": [
    "article_words = nltk.word_tokenize(article_text)\n",
    "print(article_words[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Lemmatization\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "wnlemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def perform_lemmatization(tokens):\n",
    "    return [wnlemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "\n",
    "punctuation_removal = {\n",
    "    ord(punctuation): None\n",
    "    for punctuation in string.punctuation\n",
    "}\n",
    "\n",
    "\n",
    "def get_processed_text(document: str):\n",
    "    return perform_lemmatization(nltk.word_tokenize(document.lower().translate(punctuation_removal)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{33: None, 34: None, 35: None, 36: None, 37: None, 38: None, 39: None, 40: None, 41: None, 42: None, 43: None, 44: None, 45: None, 46: None, 47: None, 58: None, 59: None, 60: None, 61: None, 62: None, 63: None, 64: None, 91: None, 92: None, 93: None, 94: None, 95: None, 96: None, 123: None, 124: None, 125: None, 126: None}\n"
     ]
    }
   ],
   "source": [
    "print(punctuation_removal)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Responding to Greetings\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "greeting_inputs =(\n",
    "    'hey',\n",
    "    'good morning',\n",
    "    'good evening',\n",
    "    'morning',\n",
    "    'evening',\n",
    "    'hi',\n",
    "    'whatsup',\n",
    ")\n",
    "\n",
    "greeting_responses = [\n",
    "    'hey',\n",
    "    'hey hows you?',\n",
    "    '*nods*',\n",
    "    'hello, how you doing',\n",
    "    'hello, how you doing',\n",
    "    'hello',\n",
    "    'you are welcome',\n",
    "]\n",
    "\n",
    "def generate_greeting_response(greeting: str) -> str:\n",
    "    for token in greeting.split():\n",
    "        if token.lower() in greeting_inputs:\n",
    "            return random.choice(greeting_responses)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Responding to User Queries\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def generate_response(user_input: str) -> str:\n",
    "    sentences = [*article_sentence, user_input]\n",
    "\n",
    "    word_vectorizer = TfidfVectorizer(\n",
    "        tokenizer=get_processed_text,\n",
    "        stop_words='english'\n",
    "    )\n",
    "\n",
    "    all_word_vectors = word_vectorizer.fit_transform(sentences)\n",
    "    similarly_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)\n",
    "    similar_sentence_number = similarly_vector_values.argsort()[0][-2]\n",
    "\n",
    "    matched_vector = similarly_vector_values.flatten()\n",
    "    matched_vector.sort()\n",
    "    vector_matched = matched_vector[-2]\n",
    "\n",
    "    if vector_matched == 0:\n",
    "        return \"I'm sorry, I could not understand you.\"\n",
    "    else:\n",
    "        return article_sentence[similar_sentence_number]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/volodymyrb/PycharmProjects/AIBot/venv/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:383: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"diogenes laërtius states that the same theano was pythagoras's pupil and that pythagoras's wife theano was her daughter.\""
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response('Who Pythagoras was?')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-cc5313b7",
   "language": "python",
   "display_name": "PyCharm (AIBot)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}